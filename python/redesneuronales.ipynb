{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales\n",
    "\n",
    "Para realizar una comparación empezamos utilizando los árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duración del proceso: 1.703125 segundos\n",
      "Mejor configuración paramétrica: {'max_depth': 4, 'min_samples_split': 49}\n",
      "Tasa de acierto en validación de la mejor configuración: 0.9208866155157714\n",
      "Estimación del rendimiento real: 0.8903508771929824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer  \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  \n",
    "from sklearn import tree  \n",
    "import time  \n",
    "  \n",
    "dataset = load_breast_cancer() # Carga del dataset Breast cancer  \n",
    "X, y = dataset.data, dataset.target;  \n",
    "X_entrenamiento, X_test, y_entrenamiento, y_test =  train_test_split(X,y, test_size=0.4, random_state=13)  \n",
    "# Definición de los rangos de los parámetros  \n",
    "parametros_a_ajustar = [{'max_depth': [4,5,6],   \n",
    "                         'min_samples_split': range(2, 51)}]  \n",
    "  \n",
    "# Búsqueda en rejilla con validación cruzada \n",
    "# sobre la muestra de entrenamiento  \n",
    "comienzo = time.process_time()  \n",
    "arbol = GridSearchCV(tree.DecisionTreeClassifier(),\n",
    "parametros_a_ajustar,cv=5)  \n",
    "arbol.fit(X_entrenamiento, y_entrenamiento)  \n",
    "print(\"Duración del proceso:\",\n",
    "time.process_time()-comienzo,\"segundos\")  \n",
    "        \n",
    "# Salida de resultados de la búsqueda  \n",
    "print(\"Mejor configuración paramétrica:\",arbol.best_params_)  \n",
    "print(\"Tasa de acierto en validación de la mejor configuración:\",\n",
    "arbol.best_score_)  \n",
    "print(\"Estimación del rendimiento real:\", arbol.score(X_test, y_test))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo, pero con el perceptrón multicapa muy simple, con una única capa oculta con solo una neurona. \n",
    "\n",
    "El módulo de *scikit-learn* para redes neuronales es `neural_network`, del que importaremos la función `MLPClassifier`, la versión para clasificación del perceptrón multicapa (Multi-Layer Perceptron). \n",
    "\n",
    "\n",
    "En el código que sigue, para especificar el número de capas y de neuronas por capa se utiliza el parámetro hidden_layer_sizes, de modo que por ejemplo hidden_layer_sizes = (5,3) requerirá el ajuste de una red con dos capas ocultas, la primera con 5 neuronas y la segunda con 3. La red de una única neurona que se entrenará se especifica entonces con hidden_layer_sizes = (1,). De igual modo, para requerir el uso de funciones de activación logísticas, se ha de especificar activation = 'logistic'. Las expresiones solver = 'sgd' y batch_size = 1 requieren respectivamente el uso del algoritmo habitual de descenso del gradiente para el entrenamiento por retropropagación, y que la actualización de los pesos se realice tras procesar cada ejemplo. Además, se especifica que el entrenamiento lleve a cabo un máximo de max_iter = 50 epochs o vueltas completas al conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duración del proceso: 2.8125\n",
      "Estimación del rendimiento real: 0.9605263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rafa\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalización de los inputs  \n",
    "scaler = MinMaxScaler()  \n",
    "scaler.fit(X)  \n",
    "X = scaler.transform(X)  \n",
    "\n",
    "# Conjuntos de entrenamiento y test normalizados  \n",
    "X_entrenamiento, X_test, y_entrenamiento, y_test = train_test_split(X,y, test_size=0.4, random_state=13)\n",
    "\n",
    "# Entrenamiento de la red \n",
    "comienzo=time.process_time()  \n",
    "red = MLPClassifier(hidden_layer_sizes=(1,), activation='logistic',\n",
    " \tsolver='sgd',\n",
    " \t\t\t\t\tbatch_size=1, max_iter=50, random_state=0);  \n",
    "red.fit(X_entrenamiento,y_entrenamiento)  \n",
    "print(\"Duración del proceso:\",time.process_time()-comienzo)  \n",
    "print(\"Estimación del rendimiento real:\", red.score(X_test, y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
